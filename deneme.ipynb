{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94397a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 13:29:08,499 - numexpr.utils - INFO\n",
      "Msg: NumExpr defaulting to 8 threads.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "import zemberek\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import stanfordnlp\n",
    "import stanza\n",
    "from gensim import utils\n",
    "from lemmatizer import ret_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab90c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tknz_tr(inp, token_min_len=2, token_max_len=100, lower=True):\n",
    "    #TODO : MorphAnalyzer ile lemmatization yada stemming ?\n",
    "    \"\"\"sw = []\n",
    "    for line in (open('/content/drive/MyDrive/stopwords.txt','r', encoding=\"utf-8\")).readlines():\n",
    "        sw.append(line.rstrip('\\n'))\"\"\"\n",
    "    lowerMap = {ord(u'A'): u'a',ord(u'A'): u'a',ord(u'B'): u'b',ord(u'C'): u'c',ord(u'Ç'): u'ç',ord(u'D'): u'd',ord(u'E'): u'e',ord(u'F'): u'f',ord(u'G'): u'g',ord(u'Ğ'): u'ğ',ord(u'H'): u'h',ord(u'I'): u'ı',ord(u'İ'): u'i',ord(u'J'): u'j',ord(u'K'): u'k',ord(u'L'): u'l',ord(u'M'): u'm',ord(u'N'): u'n',ord(u'O'): u'o',ord(u'Ö'): u'ö',ord(u'P'): u'p',ord(u'R'): u'r',ord(u'S'): u's',ord(u'Ş'): u'ş',ord(u'T'): u't',ord(u'U'): u'u',ord(u'Ü'): u'ü',ord(u'V'): u'v',ord(u'Y'): u'y',ord(u'Z'): u'z'}\n",
    "    inp = inp.translate(lowerMap)\n",
    "    tokenizer = TurkishTokenizer.DEFAULT\n",
    "    tknL = tokenizer.tokenize(inp)\n",
    "    ls = []\n",
    "    for token in tknL:\n",
    "        if(not token.content.startswith(\"_\") and (token_min_len <= len(token.content) <= token_max_len) and (token.content not in stp)):\n",
    "            ls.append(utils.to_unicode(token.content))\n",
    "    return [ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2566347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ağaç_1', 'ağa_1', 'ağ_1', 'a_1']\n"
     ]
    }
   ],
   "source": [
    "res = ret_fin(\"ağacı\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d337129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 13:34:20,454 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 9.932389974594116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "morph = TurkishMorphology.create_with_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdf29cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[koşmak:Verb] koş:Verb|ucu:Agt→Adj\n",
      "koşmak\n"
     ]
    }
   ],
   "source": [
    "res = morph.analyze(\"koşucu\")\n",
    "for e in res.analysis_results:\n",
    "    print(e)\n",
    "    ##print(e.get_stem())\n",
    "    print(e.item.lemma)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38919f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
